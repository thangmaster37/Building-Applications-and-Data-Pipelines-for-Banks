import pandas as pd
import io
# Read single parquet file from S3
def pd_read_s3_parquet(s3_client, key, bucket, **args):
    obj = s3_client.get_object(Bucket=bucket, Key=key)
    return pd.read_parquet(io.BytesIO(obj['Body'].read()), **args)

# Read multiple parquets from a folder on S3 generated by spark
def pd_read_s3_multiple_parquets(s3_client, filepath, bucket, verbose=False, **args):
    if not filepath.endswith('/'):
        filepath = filepath + '/'  # Add '/' to the end
    response = s3_client.list_objects_v2(Bucket=bucket, Prefix=filepath)
    s3_keys = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.parquet')]
    if not s3_keys:
        print('No parquet found in', bucket, filepath)
    elif verbose:
        print('Load parquets:')
        for p in s3_keys: 
            print(p)
    dfs = [pd_read_s3_parquet(s3_client, key, bucket=bucket, **args) 
        for key in s3_keys]
    return pd.concat(dfs, ignore_index=True)